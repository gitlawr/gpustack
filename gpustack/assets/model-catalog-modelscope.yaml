draft_models:
- name: Qwen3-8B-EAGLE3
  algorithm: eagle3
  source: model_scope
  model_scope_model_id: gpustack/qwen3_8b_eagle3
- name: Qwen3-30B-A3B-EAGLE3
  algorithm: eagle3
  source: model_scope
  model_scope_model_id: gpustack/qwen3_30b_moe_eagle3
- name: Qwen3-235B-A22B-EAGLE3
  algorithm: eagle3
  source: model_scope
  model_scope_model_id: gpustack/Qwen3-235B-A22B-EAGLE3
- name: gpt-oss-120b-EAGLE3
  algorithm: eagle3
  source: model_scope
  model_scope_model_id: gpustack/EAGLE3-gpt-oss-120b-bf16
model_sets:
- name: Qwen3 30B A3B
  description: The updated version of the Qwen3-30B-A3B non-thinking mode.
  home: https://modelscope.com/Qwen/Qwen3-30B-A3B
  icon: /static/catalog_icons/qwen.png
  size: 30
  activated_size: 3 
  categories:
    - llm
  capabilities:
    - context/1M
    - tools
  licenses:
    - apache-2.0
  release_date: "2025-07-21"
  recipes:
    - mode: throughput
      quantization: FP8
      source: model_scope
      model_scope_model_id: Qwen/Qwen3-30B-A3B-FP8
      gpu_filters:
      - gpu_type: H100
        gpu_count: 1
      backend: SGLang
      backend_parameters:
        - --reasoning-parser=qwen3
        - --tool-call-parser=qwen25
    - mode: latency
      quantization: FP8
      source: model_scope
      model_scope_model_id: Qwen/Qwen3-30B-A3B-FP8
      gpu_filters:
      - gpu_type: H100
        gpu_count: 1
      speculative_config:
        enabled: true
        algorithm: eagle3
        draft_model_name: Qwen3-30B-A3B-EAGLE3
        num_draft_tokens: 8
      backend: SGLang
      backend_parameters:
        - --reasoning-parser=qwen3
        - --tool-call-parser=qwen25
        - --speculative-algorithm=EAGLE3
        - --speculative-draft-model-path=Tengyunw/qwen3_30b_moe_eagle3
        - --speculative-num-steps=6
        - --speculative-eagle-topk=10
        - --speculative-num-draft-tokens=32
    - mode: reference
      quantization: BF16
      source: model_scope
      model_scope_model_id: Qwen/Qwen3-30B-A3B
      backend: vLLM
      backend_parameters:
        - --tool-call-parser=hermes
        - --enable-auto-tool-choice
        - --max-model-len=32768
- name: GLM-4.6
  description: GLM-4.6 is a large language model developed by Zhipu AI, featuring advanced agentic, reasoning, and coding capabilities.
  home: https://modelscope.com/ZhipuAI/GLM-4.6
  icon: /static/catalog_icons/zai.png
  size: 355
  activated_size: 32
  categories:
    - llm
  capabilities:
    - context/1M
    - reasoning
    - tools
  licenses:
    - mit
  release_date: "2025-09-30"
  recipes:
    - mode: throughput
      quantization: FP8
      source: model_scope
      model_scope_model_id: ZhipuAI/GLM-4.6-FP8
      gpu_filters:
      - gpu_type: "H100"
        gpu_count: 8
      backend: SGLang
      backend_parameters:
        - --reasoning-parser=glm45
        - --tool-call-parser=glm45
        - --tp-size=8
        - --ep-size=8
    - mode: throughput
      quantization: FP8
      source: model_scope
      model_scope_model_id: ZhipuAI/GLM-4.6-FP8
      gpu_filters:
      - gpu_type: "A100"
        gpu_count: 8
      backend: SGLang
      backend_parameters:
        - --reasoning-parser=glm45
        - --tool-call-parser=glm45
        - --enable-auto-tool-choice
        - --max-num-batched-tokens=8192
        - --tp-size=8
    - mode: latency
      quantization: FP8
      source: model_scope
      model_scope_model_id: ZhipuAI/GLM-4.6
      speculative_config:
        enabled: true
        algorithm: mtp
        num_draft_tokens: 4
      backend: SGLang
      backend_parameters:
        - --reasoning-parser=glm45
        - --tool-call-parser=glm45
    - mode: reference
      quantization: BF16
      source: model_scope
      model_scope_model_id: ZhipuAI/GLM-4.6
      backend: vLLM
      backend_parameters:
        - --reasoning-parser=glm45
        - --tool-call-parser=glm45
        - --enable-auto-tool-choice
        - --max-model-len=32768
# Embedding models
- name: Qwen3 Embedding 0.6B
  description: Qwen3-Embedding is a multilingual embedding model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 0.6
  categories:
    - embedding
  capabilities:
    - dimensions/4096
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  templates:
    - mode: reference
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Embedding-0.6B
      categories:
        - embedding
      backend: vLLM
      backend_parameters:
        - --task=embed
- name: Qwen3 Embedding 4B
  description: Qwen3-Embedding is a multilingual embedding model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 4
  categories:
    - embedding
  capabilities:
    - dimensions/4096
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  templates:
    - mode: reference
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Embedding-4B
      categories:
        - embedding
      backend: vLLM
      backend_parameters:
        - --task=embed
- name: Qwen3 Embedding 8B
  description: Qwen3-Embedding is a multilingual embedding model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 8
  categories:
    - embedding
  capabilities:
    - dimensions/4096
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  templates:
    - mode: reference
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Embedding-8B
      categories:
        - embedding
      backend: vLLM
      backend_parameters:
        - --task=embed
# Reranker models
- name: Qwen3 Reranker 0.6B
  description: Qwen3-Reranker is a multilingual text reranking model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 0.6
  categories:
    - reranker
  capabilities:
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  templates:
    - mode: reference
      quantization: BF16
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Reranker-0.6B
      categories:
        - reranker
      env:
        GPUSTACK_APPLY_QWEN3_RERANKER_TEMPLATES: "true"
      backend: vLLM
      backend_parameters:
        - '--hf_overrides={"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
        - --task=score
- name: Qwen3 Reranker 4B
  description: Qwen3-Reranker is a multilingual text reranking model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 4
  categories:
    - reranker
  capabilities:
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  templates:
    - mode: reference
      quantization: BF16
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Reranker-4B
      categories:
        - reranker
      env:
        GPUSTACK_APPLY_QWEN3_RERANKER_TEMPLATES: "true"
      backend: vLLM
      backend_parameters:
        - '--hf_overrides={"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
        - --task=score
- name: Qwen3 Reranker 8B
  description: Qwen3-Reranker is a multilingual text reranking model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 8
  categories:
    - reranker
  capabilities:
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  templates:
    - mode: reference
      quantization: BF16
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Reranker-8B
      categories:
        - reranker
      env:
        GPUSTACK_APPLY_QWEN3_RERANKER_TEMPLATES: "true"
      backend: vLLM
      backend_parameters:
        - '--hf_overrides={"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
        - --task=score
